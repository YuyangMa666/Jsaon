{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf750d54",
   "metadata": {},
   "source": [
    "1.Key Factor for Testable Ideas:\n",
    "The key factor that makes an idea testable statistically is measurability. A hypothesis must involve variables that can be quantified and analyzed through data. If an idea cannot be operationalized or measured in numerical terms, it cannot be tested using statistical methods.\n",
    "Criteria for a Good Null Hypothesis:\n",
    "A good null hypothesis (H₀) must be:\n",
    "Clear and specific: It should state an expected outcome precisely.\n",
    "Testable: The hypothesis must allow data to either reject or fail to reject it.\n",
    "Neutral: It assumes no effect, relationship, or difference between groups, representing the \"status quo\" or baseline expectation.\n",
    "Difference Between Null and Alternative Hypotheses:\n",
    "Null Hypothesis (H₀): Assumes no effect, difference, or relationship (e.g., \"There is no difference in mean test scores between two groups\"). It is the default claim that the test aims to challenge.\n",
    "Alternative Hypothesis (H₁ or Hₐ): States the opposite of the null, proposing that there is an effect, difference, or relationship (e.g., \"There is a difference in mean test scores\"). It reflects what the researcher aims to demonstrate if the null is rejected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf8c97",
   "metadata": {},
   "source": [
    "2. These are individual data points in the sample (e.g., the test scores of individual students).\n",
    "x\n",
    "ˉ\n",
    "x\n",
    "ˉ\n",
    "  (x-bar): This is the average (mean) of the sample data points (e.g., the average test score of the students in our sample).\n",
    "μ\n",
    "μ: This is the true average (mean) for the entire population (e.g., the average test score for all students, not just the ones in the sample). This is usually unknown.\n",
    "μ\n",
    "0\n",
    "μ \n",
    "0\n",
    "​\t\n",
    " : This is the hypothesized population mean—a number we assume to be true in the null hypothesis (e.g., we assume the average test score for all students is 70)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e199194",
   "metadata": {},
   "source": [
    "3.When calculating a p-value, we assume that the null hypothesis (H₀) is true because we want to determine how unusual or extreme the observed data would be under that assumption.\n",
    "\n",
    "In other words, we're asking: \"If the null hypothesis is correct, how likely is it to observe results like the ones we got—or more extreme?\"\n",
    "\n",
    "This approach helps us gauge whether the evidence in the data is strong enough to reject the null hypothesis. If the p-value is very small, it means that such extreme data is unlikely to occur just by chance if the null hypothesis were true, leading us to question its validity. If the p-value is larger, the observed outcome is more consistent with the null hypothesis, suggesting there isn't enough evidence to reject it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f4127c",
   "metadata": {},
   "source": [
    "4.Null hypothesis (H₀): This is our starting assumption, often something like “There is no effect” or “There is no difference” (e.g., a new drug has no better effect than a placebo).\n",
    "P-value: This is the probability of observing results as extreme as ours (or even more extreme) just by random chance, assuming the null hypothesis is true.\n",
    "When the p-value is very small (e.g., 0.01 or 0.001), it means that the data we got is extremely unusual under the assumption that the null hypothesis is correct. So, the more improbable these results seem in a world where H₀ is true, the harder it is to believe the null hypothesis. It starts to look “ridiculous” or unbelievable because the observed results don’t fit the pattern we'd expect from random variation alone.\n",
    "\n",
    "In summary: A small p-value tells us, \"If the null hypothesis were true, it would be really strange to get the results we saw.\" This makes us think that the null might not be true after all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735541d6",
   "metadata": {},
   "source": [
    "5.1. Set up the null hypothesis \n",
    "H\n",
    "0\n",
    "H \n",
    "0\n",
    "​\t\n",
    " :\n",
    "\n",
    "Each couple has a 50/50 chance to tilt their heads left or right, just like flipping a fair coin.\n",
    "We're interested in how many couples tilt right.\n",
    "2. Simulate the experiment under \n",
    "H\n",
    "0\n",
    "H \n",
    "0\n",
    "​\t\n",
    " :\n",
    "\n",
    "Flip a virtual coin 124 times to simulate the head-tilt choices for 124 couples.\n",
    "Count how many times the coin lands on heads (representing a \"right\" tilt).\n",
    "Repeat this many times (e.g., 10,000 simulations) to get a sense of how often we get 80 or more \"heads\" (right tilts) by chance.\n",
    "3. Calculate the p-value:\n",
    "\n",
    "The p-value is the proportion of simulations where the number of right tilts is 80 or more.\n",
    "If this proportion is very small, it suggests that the observed result (80 right tilts) would be rare if head tilting was truly random, meaning the data provides evidence against \n",
    "H\n",
    "0\n",
    "H \n",
    "0\n",
    "​\t\n",
    " ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733cd023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "n_couples = 124         # Total number of couples\n",
    "observed_right_tilts = 80  # Observed number of couples tilting right\n",
    "n_simulations = 10000   # Number of simulations\n",
    "\n",
    "# Simulate: In each simulation, generate 124 random 50/50 coin flips (0 = left, 1 = right)\n",
    "simulated_tilts = np.random.binomial(n=n_couples, p=0.5, size=n_simulations)\n",
    "\n",
    "# Calculate the proportion of simulations with 80 or more right tilts\n",
    "p_value = np.mean(simulated_tilts >= observed_right_tilts)\n",
    "p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a22bb",
   "metadata": {},
   "source": [
    "6.No, a p-value cannot definitively prove that the null hypothesis is true or false. It only tells us how consistent the observed data is with the null hypothesis.\n",
    "\n",
    "A small p-value (e.g., 0.01) suggests that the observed result is unlikely if the null hypothesis is true, but it doesn’t prove the null hypothesis is false—there’s always a chance the result happened by random variation.\n",
    "Similarly, a large p-value doesn’t prove the null hypothesis is true—it just means the data is consistent with it, but it could still be wrong.\n",
    "For Fido’s guilt or innocence:\n",
    "\n",
    "A p-value alone cannot definitively prove innocence or guilt. It only indicates the strength of the evidence against the null (e.g., \"Fido is innocent\"). Even with very strong evidence (a tiny p-value), there's always a possibility of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3eea3",
   "metadata": {},
   "source": [
    "7.In a two-sided test, the p-value captures the probability of observing a result at least as extreme as the observed one in either direction (higher or lower than the null hypothesis). This is often done by doubling the tail probability. In contrast, for a one-sided test, we’re only interested in deviations in one direction—either higher or lower, not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e5229e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# One-sided p-value (for an increase in mean)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m p_value_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mnorm\u001b[49m\u001b[38;5;241m.\u001b[39mcdf(z)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne-sided p-value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, p_value_one_sided)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'norm' is not defined"
     ]
    }
   ],
   "source": [
    "# One-sided p-value (for an increase in mean)\n",
    "p_value_one_sided = 1 - norm.cdf(z)\n",
    "print(\"One-sided p-value:\", p_value_one_sided)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa17c2f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# One-sided p-value (for a decrease in mean)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m p_value_one_sided \u001b[38;5;241m=\u001b[39m \u001b[43mnorm\u001b[49m\u001b[38;5;241m.\u001b[39mcdf(z)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne-sided p-value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, p_value_one_sided)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'norm' is not defined"
     ]
    }
   ],
   "source": [
    "# One-sided p-value (for a decrease in mean)\n",
    "p_value_one_sided = norm.cdf(z)\n",
    "print(\"One-sided p-value:\", p_value_one_sided)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80425f3b",
   "metadata": {},
   "source": [
    "8.This experiment builds on Fisher’s famous Tea Experiment from the 1920s, where Dr. Muriel Bristol claimed she could identify whether tea or milk was poured first into her cup. Fisher designed a hypothesis test to see if she could correctly identify this by chance or if she indeed had the skill.\n",
    "\n",
    "In this modified version, 80 STA130 students are tested to see if they can identify whether milk or tea was poured first. 49 of 80 students correctly identified the order. The objective is to assess if this outcome is statistically significant or if it could reasonably occur by random guessing (null hypothesis).\n",
    "\n",
    "Relationship Between This Experiment and Fisher’s Original Experiment\n",
    "\n",
    "The original experiment involved a small, personalized test with 8 cups of tea, where Dr. Bristol had specialized knowledge. In contrast, this version involves a larger, abstract sample of students. While the original test had only 8 trials, here we have 80 students making a single judgment each. The purpose is the same: testing if the correct responses are due to chance or skill, but the nature of the population and context differs.\n",
    "\n",
    "Null and Alternative Hypotheses\n",
    "\n",
    "Null Hypothesis (\n",
    "H\n",
    "0\n",
    "H \n",
    "0\n",
    "​\t\n",
    " )\n",
    "Formal: The proportion of students who correctly identify the order of pouring is 50% (i.e., random guessing).\n",
    "H\n",
    "0\n",
    ":\n",
    "p\n",
    "=\n",
    "0.5\n",
    "H \n",
    "0\n",
    "​\t\n",
    " :p=0.5\n",
    "Informal: Students are just guessing, and their ability to correctly identify the order is no better than flipping a coin.\n",
    "Alternative Hypothesis (\n",
    "H\n",
    "1\n",
    "H \n",
    "1\n",
    "​\t\n",
    " )\n",
    "Formal: The proportion of students who correctly identify the order is greater than 50% (indicating some ability to detect the order).\n",
    "H\n",
    "1\n",
    ":\n",
    "p\n",
    ">\n",
    "0.5\n",
    "H \n",
    "1\n",
    "​\t\n",
    " :p>0.5\n",
    "Informal: Students are not just guessing—they may have some skill in identifying the pouring order.\n",
    "This is a one-sided test because we are only interested in whether the proportion of correct identifications is greater than 50% (not whether it's less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb3c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
